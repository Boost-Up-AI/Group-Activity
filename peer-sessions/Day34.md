## 피어세션 16:00~17:30

### 1. 조교님 멘토링
- Academic한 논문만 보지 말고 실제 데이터를 이용한 실용적인 논문도 구글링해서 읽어보기
- 논문구현 경험 (참고 조교님 깃허브 주소 in Slack)  \
torch.nn의 linear 같은 low-level 모듈만 사용해서 attention, multi-head attention, textCNN을 구현해보았다. \
GCN은 high-level로 구현했는데 스타를 많이 받았다.
- 그래프 데이터의 장점: 객체 간의 관계를 숫자 몇 개로 간단하게 표현할 수 있다.
- 유저와 아이템간의 유사도를 기반으로 하는 잠재인수 모형도 협업 필터의 한 종류이다.
- RMSE가 추천 시스템에서 critical한 지표는 아니다. 보통 grid search를 이용한다..?


### 2. LINE 채용설명회 (Server) 후기 by 지영님
데이터 플랫폼. 메시징 플랫폼 현업 개발자 두 명이 답변해주셨다.
- 메시지가 정확히 전달되어야 하므로 성능관리가 중요한 직무.
- 데이터 분석, 플랫폼 팀이 따로 있다. 플랫폼 팀은 머신러닝과 직접적인 관련이 없다. '머신러닝을 해봤다'고 말하려면 깊게 알고 있어야 함... 그냥 해본 정도로는 안 된다.
- 언어의 종류는 상관없고, 면접 때 그 언어를 사용해서 어떤 문제를 해결했는지 명확히 전달하기!!
- CS지식(OS, 분산시스템, 네트워크)에 대한 깊은 이해는 필수다.
- 면접관들이 자소서를 아주 꼼꼼히 읽어본다.
- 필기 테스트는 모르는 게 없을 때까지 계속 공부해라. 코딩 테스트는 생각을 구현하는 능력을 주로 보는 편. 암기식 알고리즘 공부 No!!


### 3. LINE 채용설명회 (Client) 후기 by 지호님
- 어학성적은 전혀 중요하지 않지만 어학능력이 뛰어나면 업무의 기회가 많을 수 있다.
- 프로젝트 경험은 신입에게 그렇게 중요하지는 않다. \
새로운 기술에 대한 열망이 있는지, 공부를 꾸준히 하는 사람인지, 어떤 자세로 공부하는 지를 검증하는 근거 정도로 활용된다. 프로젝트 경험이 득이 될 수도 독이 될 수도 있다. \
경험과 지식으로 사람을 뽑지는 않고 해당 분야에 대한 관심과 열정을 확인한다. 면접을 위해 공부한 건지 진짜로 공부한 건지는 질문해보면 쉽게 파악이 된다. 
- 협업이 굉장히 중요하므로 조화롭게 일할 수 있는 사람인지를 본다. 학교 생활이나 프로젝트 등의 과거 일을 통해 이를 판단한다. 또한, 많은 이용자가 서비스를 사용하기 때문에 코드를 신중하게 짜야하며 그에 따라 무거운 책임감이 필요하다.
- "프로젝트가 잘 되네. 끝!" 하지 말고 잘 되었더라도 이걸 바꿔보면 어떨까라는 식으로 생각해보는 것이 중요하다. 과거 프로젝트가 부족하더라도 뭐가 부족했는지, 어떻게 개선해야 하는지 알고 있으면 가치 있는 프로젝트이다. 공부할 때 이거는 왜 그렇지 저거는 왜 그렇지 파고 들면서 공부를 해야 기술면접 때 답변할 수 있을 것.
- 필기 테스트는 CS지식보다 알고리즘 더 많이 물어본다. 1차는 기술 위주 + 인성. 2차는 인성 위주 + 기술.
- 이런 기술을 알고 있다를 말하지 말고 "이런 기술을 라인의 서비스에 어떻게 적용하고 싶은지"를 어필할 것!!
- 현재 AI를 활용하는 것을 시도하고 있다. 하지만, 유저의 프라이버시 이슈가 있어서 온디바이스로 데이터를 익명 형태로 올려서 학습하는 게 필요할 것이다. 클라이언트의 경우 20~30MB에도 민감하기 때문에 딥러닝 모델을 배포하려면 용량 이슈가 있을 것이다.

### 4. CS지식 공부
- 지호님이 기술블로그를 통해 운영체제.알고리즘.자료구조.데이터베이스.네트워크 등의 큰 흐름을 먼저 잡고 궁금한 부분을 파고 들면서 공부하는 것을 추천해주셨습니다.  cf) 패스트캠퍼스

### 5. [거북목 주의] 바른 자세를 유지합시다!!!
- 도수치료 병원 추천 by 지영님 : [http://eomokkae.com/main](http://eomokkae.com/main)

### 6. [과제3 질문 정정]
- 과제3의 To Do (1) '모델의 파라미터 수 구하기'를 풀어보니 어제 말씀드렸던 내용에서 정정할 부분이 있습니다. 
  ### Batch normalization layer에도 trainable weight, bias가 있습니다!! 
- 그리고 어제 지영님이 convolution layer라고 하면 통상적으로 batch norm, pooling layers도 포함하는 건지 convolution만 의미하는 건지 질문해주셨습니다. 제가 생각했을 때 이번 과제에서는 batch norm도 convolution에 포함되는 것 같고 따라서 parameters 개수도 구해줘야 하는 것 같습니다. 
(근데 제가 아직 퀴즈를 채점해본 건 아니라서 혹시 틀렸으면 알려주세요ㅎㅎㅎ)
